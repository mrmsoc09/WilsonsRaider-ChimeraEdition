"""Exploit-DB Client - Production-Grade Integration

Comprehensive Exploit-DB integration with OPSEC-compliant access,
local caching, verification, and metadata enrichment.
Version: 2.0.0
"""

import os
import time
import sqlite3
import csv
import json
import hashlib
import subprocess
import shutil
import logging
from typing import Any, Dict, List, Optional
from pathlib import Path
from datetime import datetime

logger = logging.getLogger(__name__)

class ExploitDBNotConfigured(Exception):
    """Raised when Exploit-DB is not properly configured."""
    pass

class ExploitDBClient:
    """Production-grade Exploit-DB client with local mirror and caching."""

    REPO_URL = "https://github.com/offensive-security/exploitdb.git"

    def __init__(self, cache_db: Optional[str] = None, repo_dir: Optional[str] = None, auto_sync: bool = False):
        self.cache_db = Path(cache_db or os.getenv("WR_CACHE_DB", "data/exploitdb_cache.db"))
        self.repo_dir = Path(repo_dir or os.getenv("WR_EXPLOITDB_DIR", "data/exploitdb"))
        self._init_db()
        if not shutil.which("git"):
            logger.warning("git not available - local mirror sync disabled")
        if auto_sync:
            self.sync_repository()
        logger.info(f"ExploitDBClient initialized: cache={self.cache_db}")

    def _init_db(self) -> None:
        self.cache_db.parent.mkdir(parents=True, exist_ok=True)
        with sqlite3.connect(self.cache_db) as conn:
            conn.execute("""CREATE TABLE IF NOT EXISTS exploits (
                id TEXT PRIMARY KEY, title TEXT NOT NULL, description TEXT, cve TEXT,
                author TEXT, platform TEXT, type TEXT, port INTEGER, file_path TEXT,
                verified BOOLEAN DEFAULT 0, checksum TEXT, data JSON NOT NULL, cached_at INTEGER NOT NULL)""")
            conn.execute("""CREATE TABLE IF NOT EXISTS metadata (
                key TEXT PRIMARY KEY, value TEXT NOT NULL, updated_at INTEGER NOT NULL)""")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_cve ON exploits(cve)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_platform ON exploits(platform)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_type ON exploits(type)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_verified ON exploits(verified)")
            conn.commit()
        logger.debug("Exploit-DB cache database initialized")

    def sync_repository(self, depth: int = 1) -> bool:
        if not shutil.which("git"):
            logger.error("git not available for repository sync")
            return False
        try:
            self.repo_dir.parent.mkdir(parents=True, exist_ok=True)
            if not self.repo_dir.exists():
                logger.info(f"Cloning Exploit-DB repository to {self.repo_dir}")
                subprocess.run(["git", "clone", "--depth", str(depth), self.REPO_URL, str(self.repo_dir)],
                    check=True, capture_output=True, timeout=300)
                logger.info("Repository cloned successfully")
            else:
                logger.info("Updating Exploit-DB repository")
                subprocess.run(["git", "-C", str(self.repo_dir), "pull", "--rebase"],
                    check=True, capture_output=True, timeout=120)
                logger.info("Repository updated successfully")
            synced = self._parse_csv()
            self._set_metadata("last_sync", datetime.utcnow().isoformat())
            logger.info(f"Repository sync complete: {synced} exploits cached")
            return True
        except subprocess.TimeoutExpired:
            logger.error("Repository sync timeout")
            return False
        except Exception as e:
            logger.error(f"Repository sync failed: {e}")
            return False

    def _parse_csv(self) -> int:
        csv_path = self.repo_dir / "files_exploits.csv"
        if not csv_path.exists():
            logger.error(f"CSV file not found: {csv_path}")
            return 0
        count, now = 0, int(time.time())
        try:
            with sqlite3.connect(self.cache_db) as conn, open(csv_path, "r", encoding="utf-8", errors="ignore") as csvf:
                reader = csv.DictReader(csvf)
                for row in reader:
                    exploit_id = row.get("id")
                    if not exploit_id: continue
                    title = row.get("description", "")
                    cve = row.get("codes", "").strip()
                    author = row.get("author", "")
                    platform = row.get("platform", "")
                    exploit_type = row.get("type", "")
                    file_path = row.get("file", "")
                    try: port = int(row.get("port", 0))
                    except: port = 0
                    checksum = None
                    full_path = self.repo_dir / file_path if file_path else None
                    if full_path and full_path.exists():
                        checksum = self._calculate_checksum(full_path)
                    conn.execute("""REPLACE INTO exploits (id, title, description, cve, author, platform,
                        type, port, file_path, checksum, data, cached_at) VALUES (?,?,?,?,?,?,?,?,?,?,?,?)""",
                        (exploit_id, title, title, cve, author, platform, exploit_type, port, file_path, checksum, json.dumps(row), now))
                    count += 1
                conn.commit()
            logger.info(f"Parsed {count} exploits from CSV")
            return count
        except Exception as e:
            logger.error(f"Failed to parse CSV: {e}")
            return 0

    def _calculate_checksum(self, file_path: Path) -> str:
        try:
            sha256 = hashlib.sha256()
            with open(file_path, "rb") as fp:
                for chunk in iter(lambda: fp.read(8192), b""):
                    sha256.update(chunk)
            return sha256.hexdigest()
        except Exception as e:
            logger.error(f"Failed to calculate checksum: {e}")
            return ""

    def search_by_cve(self, cve: str) -> List[Dict[str, Any]]:
        with sqlite3.connect(self.cache_db) as conn:
            rows = conn.execute("SELECT data FROM exploits WHERE cve LIKE ? ORDER BY id DESC", (f"%{cve}%",)).fetchall()
            exploits = [json.loads(row[0]) for row in rows]
            logger.info(f"Found {len(exploits)} exploits for CVE: {cve}")
            return exploits

    def search_by_keyword(self, keyword: str, limit: int = 50) -> List[Dict[str, Any]]:
        with sqlite3.connect(self.cache_db) as conn:
            rows = conn.execute("""SELECT data FROM exploits WHERE title LIKE ? OR description LIKE ?
                ORDER BY id DESC LIMIT ?""", (f"%{keyword}%", f"%{keyword}%", limit)).fetchall()
            exploits = [json.loads(row[0]) for row in rows]
            logger.info(f"Found {len(exploits)} exploits for keyword: {keyword}")
            return exploits

    def search_by_platform(self, platform: str) -> List[Dict[str, Any]]:
        with sqlite3.connect(self.cache_db) as conn:
            rows = conn.execute("SELECT data FROM exploits WHERE platform = ? ORDER BY id DESC", (platform,)).fetchall()
            exploits = [json.loads(row[0]) for row in rows]
            logger.info(f"Found {len(exploits)} exploits for platform: {platform}")
            return exploits

    def get_exploit(self, exploit_id: str) -> Optional[Dict[str, Any]]:
        with sqlite3.connect(self.cache_db) as conn:
            row = conn.execute("SELECT data FROM exploits WHERE id = ?", (exploit_id,)).fetchone()
            if row: return json.loads(row[0])
        logger.warning(f"Exploit not found: {exploit_id}")
        return None

    def get_exploit_file(self, exploit_id: str) -> Optional[Path]:
        exploit = self.get_exploit(exploit_id)
        if not exploit: return None
        file_path = exploit.get("file")
        if not file_path: return None
        full_path = self.repo_dir / file_path
        if full_path.exists(): return full_path
        logger.warning(f"Exploit file not found: {full_path}")
        return None

    def verify_exploit_integrity(self, exploit_id: str) -> bool:
        with sqlite3.connect(self.cache_db) as conn:
            row = conn.execute("SELECT file_path, checksum FROM exploits WHERE id = ?", (exploit_id,)).fetchone()
            if not row:
                logger.warning(f"Exploit not found: {exploit_id}")
                return False
            file_path, stored_checksum = row
            if not file_path or not stored_checksum:
                logger.warning(f"No checksum available: {exploit_id}")
                return False
            full_path = self.repo_dir / file_path
            if not full_path.exists():
                logger.warning(f"Exploit file missing: {full_path}")
                return False
            current_checksum = self._calculate_checksum(full_path)
            verified = current_checksum == stored_checksum
            if verified:
                conn.execute("UPDATE exploits SET verified = 1 WHERE id = ?", (exploit_id,))
                conn.commit()
                logger.info(f"Exploit verified: {exploit_id}")
            else:
                logger.error(f"Exploit integrity check failed: {exploit_id}")
            return verified

    def get_stats(self) -> Dict[str, Any]:
        with sqlite3.connect(self.cache_db) as conn:
            total = conn.execute("SELECT COUNT(*) FROM exploits").fetchone()[0]
            verified = conn.execute("SELECT COUNT(*) FROM exploits WHERE verified = 1").fetchone()[0]
            platforms = conn.execute("SELECT platform, COUNT(*) as c FROM exploits GROUP BY platform ORDER BY c DESC LIMIT 10").fetchall()
            types = conn.execute("SELECT type, COUNT(*) as c FROM exploits GROUP BY type ORDER BY c DESC").fetchall()
            last_sync = self._get_metadata("last_sync", "Never")
            return {"total_exploits": total, "verified_exploits": verified,
                "top_platforms": [{"platform": p, "count": c} for p, c in platforms],
                "exploit_types": [{"type": t, "count": c} for t, c in types],
                "last_sync": last_sync, "repository_path": str(self.repo_dir)}

    def _set_metadata(self, key: str, value: str) -> None:
        with sqlite3.connect(self.cache_db) as conn:
            conn.execute("REPLACE INTO metadata (key, value, updated_at) VALUES (?, ?, ?)",
                (key, value, int(time.time())))
            conn.commit()

    def _get_metadata(self, key: str, default: str = "") -> str:
        with sqlite3.connect(self.cache_db) as conn:
            row = conn.execute("SELECT value FROM metadata WHERE key = ?", (key,)).fetchone()
            return row[0] if row else default

    def close(self) -> None:
        logger.info("ExploitDBClient closed")
